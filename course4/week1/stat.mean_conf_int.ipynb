{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Доверительные интервалы для оценки среднего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation, datasets, linear_model, metrics\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blobs = datasets.make_blobs(300, centers = 2, cluster_std = 6, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pylab.figure(figsize(8, 8))\n",
    "pylab.scatter(map(lambda x: x[0], blobs[0]), map(lambda x: x[1], blobs[0]), c = blobs[1], cmap = 'autumn',\n",
    "             s=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение линейных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Точечная оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = cross_validation.train_test_split(blobs[0], blobs[1], \n",
    "                                                                                    test_size = 15,\n",
    "                                                                                    random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ridge_model = linear_model.RidgeClassifier()\n",
    "ridge_model.fit(train_data, train_labels)\n",
    "metrics.roc_auc_score(test_labels, ridge_model.predict(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd_model = linear_model.SGDClassifier(random_state = 0)\n",
    "sgd_model.fit(train_data, train_labels)\n",
    "metrics.roc_auc_score(test_labels, sgd_model.predict(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка среднего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd_auc_scores = cross_validation.cross_val_score(linear_model.SGDClassifier(), \n",
    "                                 blobs[0], blobs[1], scoring = 'roc_auc',  \n",
    "                                 cv = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ridge_auc_scores = cross_validation.cross_val_score(linear_model.RidgeClassifier(), \n",
    "                                 blobs[0], blobs[1], scoring = 'roc_auc',  \n",
    "                                 cv = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Точечная оценка среднего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"sgd model auc: mean %.3f, std %.3f\" % (sgd_auc_scores.mean(), sgd_auc_scores.std())\n",
    "print \"ridge model auc: mean %.3f, std %.3f\" % (ridge_auc_scores.mean(), ridge_auc_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интервальная оценка среднего "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import _zconfint_generic, _tconfint_generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_mean = sgd_auc_scores.mean()\n",
    "ridge_mean = ridge_auc_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### z-интервал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, нам откуда-то известно, что дисперсия auc_scores $\\sigma^2=0.25$. Построим доверительные интервалы для средних вида $$\\bar{X}_n \\pm z_{1-\\frac{\\alpha}{2}} \\frac{\\sigma}{\\sqrt{n}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"sgd model mean auc confidence interval\", _zconfint_generic(sgd_mean, \n",
    "                                                                  sqrt(0.25/len(sgd_auc_scores)), \n",
    "                                                                  0.05, 'two-sided')\n",
    "\n",
    "print \"ridge model mean auc confidence interval\", _zconfint_generic(ridge_mean, \n",
    "                                                                    sqrt(0.25/len(sgd_auc_scores)), \n",
    "                                                                    0.05, 'two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### t-интервал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо гипотетической теоретической дисперсии $\\sigma^2$, которую мы на самом деле в данном случае не знаем, используем выборочные дисперсии, и построим доверительные интервалы вида $$\\bar{X}_n \\pm t_{1-\\frac{\\alpha}{2}} \\frac{S}{\\sqrt{n}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(sgd_auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_mean_std = sgd_auc_scores.std()/sqrt(len(sgd_auc_scores))\n",
    "ridge_mean_std = ridge_auc_scores.std()/sqrt(len(ridge_auc_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"sgd model mean auc confidence interval\", _tconfint_generic(sgd_mean, sgd_mean_std,\n",
    "                                                                    len(sgd_auc_scores) - 1,\n",
    "                                                                    0.05, 'two-sided')\n",
    "\n",
    "print \"ridge model mean auc confidence interval\", _tconfint_generic(ridge_mean, ridge_mean_std,\n",
    "                                                                      len(sgd_auc_scores) - 1,\n",
    "                                                                      0.05, 'two-sided')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
