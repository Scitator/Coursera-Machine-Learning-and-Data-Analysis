{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Идентификация пользователей по посещенным веб-страницам\n",
    "<img src='http://i.istockimg.com/file_thumbview_approve/21546327/5/stock-illustration-21546327-identification-de-l-utilisateur.jpg'>\n",
    "\n",
    "# <center>Неделя 5.  Соревнование Kaggle \"Identify Me If You Can\"\n",
    "\n",
    "На этой неделе мы вспомним про концепцию стохастического градиентного спуска и опробуем классификатор Scikit-learn SGDClassifier, который работает намного быстрее на больших выборках, чем алгоритмы, которые мы тестировали на 4 неделе. Также мы познакомимся с данными [соревнования](https://inclass.kaggle.com/c/identify-me-if-you-can-yandex-mipt/) Kaggle по идентификации пользователей и сделаем в нем первые посылки. По итогам этой недели дополнительные баллы получат те, кто попадет в топ-30 публичного лидерборда соревнования.\n",
    "\n",
    "**В этой части проекта Вам могут быть полезны видеозаписи следующих лекций курса \"Обучение на размеченных данных\":**\n",
    "   - [Стохатический градиентный спуск](https://www.coursera.org/learn/supervised-learning/lecture/xRY50/stokhastichieskii-ghradiientnyi-spusk)\n",
    "   - [Линейные модели. Sklearn.linear_model. Классификация](https://www.coursera.org/learn/supervised-learning/lecture/EBg9t/linieinyie-modieli-sklearn-linear-model-klassifikatsiia)\n",
    "   \n",
    "**Также рекомендуется вернуться и просмотреть [задание](https://www.coursera.org/learn/supervised-learning/programming/t2Idc/linieinaia-rieghriessiia-i-stokhastichieskii-ghradiientnyi-spusk) \"Линейная регрессия и стохастический градиентный спуск\" 1 недели 2 курса специализации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Считаем данные [соревнования](https://inclass.kaggle.com/c/identify-me-if-you-can-yandex-mipt/data) в DataFrame train_df и test_df (обучающая и тестовая выборки).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('kaggle_data/train_sessions.csv', index_col='session_id')\n",
    "test_df = pd.read_csv('kaggle_data/test_sessions.csv', index_col='session_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>...</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2014-01-04 08:44:50</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2014-01-04 08:44:50</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2014-01-04 08:45:19</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2014-01-04 08:45:25</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2014-01-04 08:45:25</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-01-04 08:45:51</td>\n",
       "      <td>8403.0</td>\n",
       "      <td>2014-01-04 08:45:51</td>\n",
       "      <td>932.0</td>\n",
       "      <td>2014-01-04 08:45:53</td>\n",
       "      <td>3260.0</td>\n",
       "      <td>2014-01-04 08:45:53</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2014-01-04 08:45:53</td>\n",
       "      <td>1845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111</td>\n",
       "      <td>2014-03-18 10:33:20</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2014-03-18 10:33:31</td>\n",
       "      <td>151.0</td>\n",
       "      <td>2014-03-18 10:33:31</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2014-03-18 10:33:31</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>2014-03-18 10:33:31</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-03-18 10:33:32</td>\n",
       "      <td>1375.0</td>\n",
       "      <td>2014-03-18 10:33:32</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2014-03-18 10:33:32</td>\n",
       "      <td>1401.0</td>\n",
       "      <td>2014-03-18 10:33:32</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2014-03-18 10:33:34</td>\n",
       "      <td>3322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>2014-12-02 13:13:41</td>\n",
       "      <td>3187.0</td>\n",
       "      <td>2014-12-02 13:13:41</td>\n",
       "      <td>132.0</td>\n",
       "      <td>2014-12-02 13:13:42</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2014-12-02 13:13:42</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>2014-12-02 13:13:45</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-12-02 13:13:45</td>\n",
       "      <td>3187.0</td>\n",
       "      <td>2014-12-02 13:13:45</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2014-12-02 13:13:46</td>\n",
       "      <td>3191.0</td>\n",
       "      <td>2014-12-02 13:13:46</td>\n",
       "      <td>3184.0</td>\n",
       "      <td>2014-12-02 13:13:47</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>668</td>\n",
       "      <td>2014-02-14 15:16:45</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>2014-02-14 15:17:13</td>\n",
       "      <td>598.0</td>\n",
       "      <td>2014-02-14 15:20:47</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>2014-02-14 15:21:13</td>\n",
       "      <td>284.0</td>\n",
       "      <td>2014-02-14 15:21:14</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-02-14 15:21:14</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2014-02-14 15:21:14</td>\n",
       "      <td>4451.0</td>\n",
       "      <td>2014-02-14 15:21:14</td>\n",
       "      <td>4537.0</td>\n",
       "      <td>2014-02-14 15:21:15</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2014-02-14 15:21:15</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1943</td>\n",
       "      <td>2014-03-17 15:19:40</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>2014-03-17 15:20:10</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>2014-03-17 15:21:40</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>2014-03-17 15:22:10</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>2014-03-17 15:22:39</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-03-17 15:22:39</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>2014-03-17 15:22:41</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>2014-03-17 15:22:41</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>2014-03-17 15:22:42</td>\n",
       "      <td>1943.0</td>\n",
       "      <td>2014-03-17 15:22:43</td>\n",
       "      <td>1737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1                time1   site2                time2   site3  \\\n",
       "session_id                                                                    \n",
       "1               8  2014-01-04 08:44:50    11.0  2014-01-04 08:44:50    82.0   \n",
       "2             111  2014-03-18 10:33:20    78.0  2014-03-18 10:33:31   151.0   \n",
       "3              11  2014-12-02 13:13:41  3187.0  2014-12-02 13:13:41   132.0   \n",
       "4             668  2014-02-14 15:16:45  1965.0  2014-02-14 15:17:13   598.0   \n",
       "5            1943  2014-03-17 15:19:40  1943.0  2014-03-17 15:20:10  1943.0   \n",
       "\n",
       "                          time3   site4                time4   site5  \\\n",
       "session_id                                                             \n",
       "1           2014-01-04 08:45:19    68.0  2014-01-04 08:45:25     8.0   \n",
       "2           2014-03-18 10:33:31   111.0  2014-03-18 10:33:31  1401.0   \n",
       "3           2014-12-02 13:13:42   496.0  2014-12-02 13:13:42  1969.0   \n",
       "4           2014-02-14 15:20:47  1965.0  2014-02-14 15:21:13   284.0   \n",
       "5           2014-03-17 15:21:40  1943.0  2014-03-17 15:22:10  1943.0   \n",
       "\n",
       "                          time5   ...                  time6   site7  \\\n",
       "session_id                        ...                                  \n",
       "1           2014-01-04 08:45:25   ...    2014-01-04 08:45:51  8403.0   \n",
       "2           2014-03-18 10:33:31   ...    2014-03-18 10:33:32  1375.0   \n",
       "3           2014-12-02 13:13:45   ...    2014-12-02 13:13:45  3187.0   \n",
       "4           2014-02-14 15:21:14   ...    2014-02-14 15:21:14    38.0   \n",
       "5           2014-03-17 15:22:39   ...    2014-03-17 15:22:39  1952.0   \n",
       "\n",
       "                          time7   site8                time8   site9  \\\n",
       "session_id                                                             \n",
       "1           2014-01-04 08:45:51   932.0  2014-01-04 08:45:53  3260.0   \n",
       "2           2014-03-18 10:33:32    38.0  2014-03-18 10:33:32  1401.0   \n",
       "3           2014-12-02 13:13:45    82.0  2014-12-02 13:13:46  3191.0   \n",
       "4           2014-02-14 15:21:14  4451.0  2014-02-14 15:21:14  4537.0   \n",
       "5           2014-03-17 15:22:41  1943.0  2014-03-17 15:22:41  1943.0   \n",
       "\n",
       "                          time9  site10               time10 user_id  \n",
       "session_id                                                            \n",
       "1           2014-01-04 08:45:53     8.0  2014-01-04 08:45:53    1845  \n",
       "2           2014-03-18 10:33:32    97.0  2014-03-18 10:33:34    3322  \n",
       "3           2014-12-02 13:13:46  3184.0  2014-12-02 13:13:47    2003  \n",
       "4           2014-02-14 15:21:15    11.0  2014-02-14 15:21:15    1373  \n",
       "5           2014-03-17 15:22:42  1943.0  2014-03-17 15:22:43    1737  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Объединим обучающую и тестовую выборки – это понадобится, чтоб вместе потом привести их к разреженному формату.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test_df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обучающей выборке видим следующие признаки:\n",
    "    - site1 – индекс первого посещенного сайта в сессии\n",
    "    - time1 – время посещения первого сайта в сессии\n",
    "    - ...\n",
    "    - site10 – индекс 10-го посещенного сайта в сессии\n",
    "    - time10 – время посещения 10-го сайта в сессии\n",
    "    - user_id – ID пользователя\n",
    "    \n",
    "Сессии пользователей выделены таким образом, что они не могут быть длинее получаса или 10 сайтов. То есть сессия считается оконченной либо когда пользователь посетил 10 сайтов подряд, либо когда сессия заняла по времени более 30 минут. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на статистику признаков.**\n",
    "\n",
    "Пропуски возникают там, где сессии короткие (менее 10 сайтов). Скажем, если человек 1 января 2015 года посетил *vk.com* в 20:01, потом *yandex.ru* в 20:29, затем *google.com* в 20:33, то первая его сессия будет состоять только из двух сайтов (site1 – ID сайта *vk.com*, time1 – 2015-01-01 20:01:00, site2 – ID сайта  *yandex.ru*, time2 – 2015-01-01 20:29:00, остальные признаки – NaN), а начиная с *google.com* пойдет новая сессия, потому что уже прошло более 30 минут с момента посещения *vk.com*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 95319 entries, 1 to 95319\n",
      "Data columns (total 21 columns):\n",
      "site1      95319 non-null int64\n",
      "time1      95319 non-null object\n",
      "site2      93722 non-null float64\n",
      "time2      93722 non-null object\n",
      "site3      92339 non-null float64\n",
      "time3      92339 non-null object\n",
      "site4      91085 non-null float64\n",
      "time4      91085 non-null object\n",
      "site5      89868 non-null float64\n",
      "time5      89868 non-null object\n",
      "site6      88776 non-null float64\n",
      "time6      88776 non-null object\n",
      "site7      87755 non-null float64\n",
      "time7      87755 non-null object\n",
      "site8      86738 non-null float64\n",
      "time8      86738 non-null object\n",
      "site9      85754 non-null float64\n",
      "time9      85754 non-null object\n",
      "site10     84810 non-null float64\n",
      "time10     84810 non-null object\n",
      "user_id    95319 non-null int64\n",
      "dtypes: float64(9), int64(2), object(10)\n",
      "memory usage: 16.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>time1</th>\n",
       "      <th>site2</th>\n",
       "      <th>time2</th>\n",
       "      <th>site3</th>\n",
       "      <th>time3</th>\n",
       "      <th>site4</th>\n",
       "      <th>time4</th>\n",
       "      <th>site5</th>\n",
       "      <th>time5</th>\n",
       "      <th>site6</th>\n",
       "      <th>time6</th>\n",
       "      <th>site7</th>\n",
       "      <th>time7</th>\n",
       "      <th>site8</th>\n",
       "      <th>time8</th>\n",
       "      <th>site9</th>\n",
       "      <th>time9</th>\n",
       "      <th>site10</th>\n",
       "      <th>time10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1917</td>\n",
       "      <td>2014-12-04 20:36:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20225</td>\n",
       "      <td>2014-03-04 14:08:55</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2014-03-04 14:08:59</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2014-03-04 14:08:59</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2014-03-04 14:09:50</td>\n",
       "      <td>20225.0</td>\n",
       "      <td>2014-03-04 14:10:43</td>\n",
       "      <td>20258.0</td>\n",
       "      <td>2014-03-04 14:10:44</td>\n",
       "      <td>20225.0</td>\n",
       "      <td>2014-03-04 14:10:45</td>\n",
       "      <td>20225.0</td>\n",
       "      <td>2014-03-04 14:11:07</td>\n",
       "      <td>20276.0</td>\n",
       "      <td>2014-03-04 14:11:08</td>\n",
       "      <td>20225.0</td>\n",
       "      <td>2014-03-04 14:11:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>2014-03-31 09:20:38</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2014-03-31 09:20:42</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2014-03-31 09:20:43</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2014-03-31 09:20:43</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2014-03-31 09:20:43</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2014-03-31 09:20:45</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2014-03-31 09:20:46</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2014-03-31 09:20:47</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2014-03-31 09:20:48</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2014-03-31 09:20:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7338</td>\n",
       "      <td>2014-02-14 13:39:36</td>\n",
       "      <td>7338.0</td>\n",
       "      <td>2014-02-14 14:07:53</td>\n",
       "      <td>7338.0</td>\n",
       "      <td>2014-02-14 14:08:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19622</td>\n",
       "      <td>2014-03-31 09:46:04</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2014-03-31 09:46:12</td>\n",
       "      <td>340.0</td>\n",
       "      <td>2014-03-31 09:46:13</td>\n",
       "      <td>19634.0</td>\n",
       "      <td>2014-03-31 09:46:14</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>2014-03-31 09:46:14</td>\n",
       "      <td>327.0</td>\n",
       "      <td>2014-03-31 09:46:15</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2014-03-31 09:46:19</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>2014-03-31 09:46:19</td>\n",
       "      <td>340.0</td>\n",
       "      <td>2014-03-31 09:46:20</td>\n",
       "      <td>19634.0</td>\n",
       "      <td>2014-03-31 09:46:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1                time1   site2                time2   site3  \\\n",
       "session_id                                                                    \n",
       "1            1917  2014-12-04 20:36:21     NaN                  NaN     NaN   \n",
       "2           20225  2014-03-04 14:08:55    27.0  2014-03-04 14:08:59     9.0   \n",
       "3              71  2014-03-31 09:20:38    63.0  2014-03-31 09:20:42    64.0   \n",
       "4            7338  2014-02-14 13:39:36  7338.0  2014-02-14 14:07:53  7338.0   \n",
       "5           19622  2014-03-31 09:46:04    32.0  2014-03-31 09:46:12   340.0   \n",
       "\n",
       "                          time3    site4                time4    site5  \\\n",
       "session_id                                                               \n",
       "1                           NaN      NaN                  NaN      NaN   \n",
       "2           2014-03-04 14:08:59     32.0  2014-03-04 14:09:50  20225.0   \n",
       "3           2014-03-31 09:20:43     63.0  2014-03-31 09:20:43     71.0   \n",
       "4           2014-02-14 14:08:36      NaN                  NaN      NaN   \n",
       "5           2014-03-31 09:46:13  19634.0  2014-03-31 09:46:14   1721.0   \n",
       "\n",
       "                          time5    site6                time6    site7  \\\n",
       "session_id                                                               \n",
       "1                           NaN      NaN                  NaN      NaN   \n",
       "2           2014-03-04 14:10:43  20258.0  2014-03-04 14:10:44  20225.0   \n",
       "3           2014-03-31 09:20:43     22.0  2014-03-31 09:20:45     64.0   \n",
       "4                           NaN      NaN                  NaN      NaN   \n",
       "5           2014-03-31 09:46:14    327.0  2014-03-31 09:46:15     38.0   \n",
       "\n",
       "                          time7    site8                time8    site9  \\\n",
       "session_id                                                               \n",
       "1                           NaN      NaN                  NaN      NaN   \n",
       "2           2014-03-04 14:10:45  20225.0  2014-03-04 14:11:07  20276.0   \n",
       "3           2014-03-31 09:20:46     71.0  2014-03-31 09:20:47     71.0   \n",
       "4                           NaN      NaN                  NaN      NaN   \n",
       "5           2014-03-31 09:46:19   1721.0  2014-03-31 09:46:19    340.0   \n",
       "\n",
       "                          time9   site10               time10  \n",
       "session_id                                                     \n",
       "1                           NaN      NaN                  NaN  \n",
       "2           2014-03-04 14:11:08  20225.0  2014-03-04 14:11:09  \n",
       "3           2014-03-31 09:20:48     70.0  2014-03-31 09:20:51  \n",
       "4                           NaN      NaN                  NaN  \n",
       "5           2014-03-31 09:46:20  19634.0  2014-03-31 09:46:20  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41177 entries, 1 to 41177\n",
      "Data columns (total 20 columns):\n",
      "site1     41177 non-null int64\n",
      "time1     41177 non-null object\n",
      "site2     39529 non-null float64\n",
      "time2     39529 non-null object\n",
      "site3     38158 non-null float64\n",
      "time3     38158 non-null object\n",
      "site4     37030 non-null float64\n",
      "time4     37030 non-null object\n",
      "site5     36049 non-null float64\n",
      "time5     36049 non-null object\n",
      "site6     35083 non-null float64\n",
      "time6     35083 non-null object\n",
      "site7     34284 non-null float64\n",
      "time7     34284 non-null object\n",
      "site8     33434 non-null float64\n",
      "time8     33434 non-null object\n",
      "site9     32633 non-null float64\n",
      "time9     32633 non-null object\n",
      "site10    31907 non-null float64\n",
      "time10    31907 non-null object\n",
      "dtypes: float64(9), int64(1), object(10)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В обучающей выборке – 550 пользователей.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3165    3351\n",
       "537     1927\n",
       "3324    1534\n",
       "1826    1528\n",
       "1845    1452\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['user_id'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пока для прогноза ID пользователя будем использовать только индексы посещенных сайтов. Индексы нумеровались с 1, так что заменим пропуски на нули.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_test_df_sites = train_test_df[\n",
    "    ['site1', 'site2', 'site3', \n",
    "     'site4','site5', \n",
    "     'site6','site7', 'site8', \n",
    "     'site9', 'site10']].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site1</th>\n",
       "      <th>site2</th>\n",
       "      <th>site3</th>\n",
       "      <th>site4</th>\n",
       "      <th>site5</th>\n",
       "      <th>site6</th>\n",
       "      <th>site7</th>\n",
       "      <th>site8</th>\n",
       "      <th>site9</th>\n",
       "      <th>site10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>82</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>8393</td>\n",
       "      <td>8403</td>\n",
       "      <td>932</td>\n",
       "      <td>3260</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111</td>\n",
       "      <td>78</td>\n",
       "      <td>151</td>\n",
       "      <td>111</td>\n",
       "      <td>1401</td>\n",
       "      <td>151</td>\n",
       "      <td>1375</td>\n",
       "      <td>38</td>\n",
       "      <td>1401</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>3187</td>\n",
       "      <td>132</td>\n",
       "      <td>496</td>\n",
       "      <td>1969</td>\n",
       "      <td>504</td>\n",
       "      <td>3187</td>\n",
       "      <td>82</td>\n",
       "      <td>3191</td>\n",
       "      <td>3184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>668</td>\n",
       "      <td>1965</td>\n",
       "      <td>598</td>\n",
       "      <td>1965</td>\n",
       "      <td>284</td>\n",
       "      <td>668</td>\n",
       "      <td>38</td>\n",
       "      <td>4451</td>\n",
       "      <td>4537</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1943</td>\n",
       "      <td>1943</td>\n",
       "      <td>1943</td>\n",
       "      <td>1943</td>\n",
       "      <td>1943</td>\n",
       "      <td>1952</td>\n",
       "      <td>1952</td>\n",
       "      <td>1943</td>\n",
       "      <td>1943</td>\n",
       "      <td>1943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2941</td>\n",
       "      <td>2951</td>\n",
       "      <td>2958</td>\n",
       "      <td>2993</td>\n",
       "      <td>162</td>\n",
       "      <td>2967</td>\n",
       "      <td>85</td>\n",
       "      <td>7</td>\n",
       "      <td>2967</td>\n",
       "      <td>2967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9996</td>\n",
       "      <td>9996</td>\n",
       "      <td>307</td>\n",
       "      <td>9996</td>\n",
       "      <td>280</td>\n",
       "      <td>9996</td>\n",
       "      <td>9996</td>\n",
       "      <td>307</td>\n",
       "      <td>9996</td>\n",
       "      <td>9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19823</td>\n",
       "      <td>19823</td>\n",
       "      <td>1510</td>\n",
       "      <td>32</td>\n",
       "      <td>19808</td>\n",
       "      <td>8</td>\n",
       "      <td>567</td>\n",
       "      <td>567</td>\n",
       "      <td>654</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>561</td>\n",
       "      <td>69</td>\n",
       "      <td>32</td>\n",
       "      <td>329</td>\n",
       "      <td>329</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            site1  site2  site3  site4  site5  site6  site7  site8  site9  \\\n",
       "session_id                                                                  \n",
       "1               8     11     82     68      8   8393   8403    932   3260   \n",
       "2             111     78    151    111   1401    151   1375     38   1401   \n",
       "3              11   3187    132    496   1969    504   3187     82   3191   \n",
       "4             668   1965    598   1965    284    668     38   4451   4537   \n",
       "5            1943   1943   1943   1943   1943   1952   1952   1943   1943   \n",
       "6            2941   2951   2958   2993    162   2967     85      7   2967   \n",
       "7            9996   9996    307   9996    280   9996   9996    307   9996   \n",
       "8           19823  19823   1510     32  19808      8    567    567    654   \n",
       "9              72      0      0      0      0      0      0      0      0   \n",
       "10             32     32    561     69     32    329    329     69     69   \n",
       "\n",
       "            site10  \n",
       "session_id          \n",
       "1                8  \n",
       "2               97  \n",
       "3             3184  \n",
       "4               11  \n",
       "5             1943  \n",
       "6             2967  \n",
       "7             9996  \n",
       "8              567  \n",
       "9                0  \n",
       "10             329  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_df_sites.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136496, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_df_sites.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте разреженные матрицы *X_train_sparse* и *X_test_sparse* аналогично тому, как мы это делали ранее. Используйте объединенную матрицу train_test_df_sites – потом разделите обратно на обучающую и тестовую части.**\n",
    "\n",
    "Обратите внимание на то, что в  сессиях меньше 10 сайтов  у нас остались нули, так что первый признак (сколько раз попался 0) по смыслу отличен от остальных (сколько раз попался сайт с индексом $i$). Поэтому первый столбец разреженной матрицы надо будет удалить.\n",
    "\n",
    "**Выделите в отдельный вектор *y* ответы на обучающей выборке.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_sparse(X_toy):\n",
    "    indptr = [0]\n",
    "    indices = []\n",
    "    data = []\n",
    "    for d in X_toy:\n",
    "        for term in d:\n",
    "            index = term\n",
    "            indices.append(index)\n",
    "            data.append(1)\n",
    "        indptr.append(len(indices))\n",
    "    X_sparse_toy = csr_matrix((data, indices, indptr), dtype=int)[:,1:]\n",
    "    return X_sparse_toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_test_sparse = to_sparse(train_test_df_sites.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_sparse = X_train_test_sparse[:train_df.shape[0], :]\n",
    "X_test_sparse = X_train_test_sparse[train_df.shape[0]:, :]\n",
    "y = train_df['user_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, file_address):\n",
    "    with open(file_address, 'w') as out_f:\n",
    "        out_f.write(str(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запишите в файл *answer5_1.txt* размерности матриц *X_train_sparse* и *X_test_sparse* – 4 числа на одной строке через пробел: число строк и столбцов матрицы *X_train_sparse*, затем число строк и столбцов матрицы *X_test_sparse*. Полученный файл будет ответом на 1 вопрос теста.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res1 = \" \".join(map(str, \n",
    "             list(chain.from_iterable(\n",
    "                [X_train_sparse.shape, X_test_sparse.shape]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_answer_to_file(res1,\n",
    "                      'answer5_1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сохраним в pickle-файлы объекты *X_train_sparse*, *X_test_sparse* и *y* (последний – в файл *kaggle_data/train_target.pkl*).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('kaggle_data/X_train_sparse.pkl', 'wb') as X_train_sparse_pkl:\n",
    "    pickle.dump(X_train_sparse, X_train_sparse_pkl)\n",
    "with open('kaggle_data/X_test_sparse.pkl', 'wb') as X_test_sparse_pkl:\n",
    "    pickle.dump(X_test_sparse, X_test_sparse_pkl)\n",
    "with open('kaggle_data/train_target.pkl', 'wb') as train_target_pkl:\n",
    "    pickle.dump(y, train_target_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разобьем обучающую выборку на 2 части в пропорции 7/3.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_sparse, y, test_size=0.3, \n",
    "    random_state=7, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Создайте объекты sklearn.linear_model.SGDClassifier с логистической функцией потерь и с hinge loss (логистическая регрессия и линейный SVM соответственно) и параметром random_state=7. Остальные параметры оставьте по умолчанию, разве что n_jobs=-1 никогда не помешает. Обучите  модели на выборке (X_train, y_train).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_logit = SGDClassifier(loss=\"log\", random_state=7, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.3 s, sys: 300 ms, total: 56.6 s\n",
      "Wall time: 15.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=-1,\n",
       "       penalty='l2', power_t=0.5, random_state=7, shuffle=True, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sgd_logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_svm = SGDClassifier(loss=\"hinge\", random_state=7, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.5 s, sys: 96.7 ms, total: 39.6 s\n",
      "Wall time: 10.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=-1,\n",
       "       penalty='l2', power_t=0.5, random_state=7, shuffle=True, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sgd_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сделаем прогнозы с помощью обеих моделей на отложенной выборке (X_valid, y_valid).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit_valid_pred = sgd_logit.predict(X_valid)\n",
    "svm_valid_pred = sgd_svm.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.286403692824\n",
      "0.267135263673\n"
     ]
    }
   ],
   "source": [
    "logit_accuracy_score = accuracy_score(y_valid, logit_valid_pred)\n",
    "svm_accuracy_score = accuracy_score(y_valid, svm_valid_pred)\n",
    "print(logit_accuracy_score)\n",
    "print(svm_accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запишите в файл *answer5_2.txt* через пробел доли правильных ответов логистической регресии и линейного SVM, обученных с помощью стохастического градиентного спуска, на отложенной выборке. Округлите до 3 знаков после разделителя. Полученный файл будет ответом на 2 вопрос теста.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_answer_to_file(\"{} {}\".format(round(logit_accuracy_score, 3), \n",
    "                                    round(svm_accuracy_score, 3)),\n",
    "                     'answer5_2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сделайте прогноз для тестовой выборки с помощью sgd_logit.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit_test_pred = ''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запишите ответы в файл и сделайте посылку на Kaggle. Далее будет короткое Peer-Review задание, в котором надо проверить посылки друг друга на Kaggle. Поэтому дайте своей команде (из одного человека) на Kaggle говорящее название – по шаблону \"[YDF & MIPT] Coursera Username\", чтоб можно было идентифицировать Вашу посылку на [лидерборде](https://inclass.kaggle.com/c/identify-me-if-you-can-yandex-mipt/leaderboard).**\n",
    "\n",
    "**Результат, который мы только что получили, соответствует бейзлайну \"SGDCLassifer\" на лидерборде, задача на эту неделю – как минимум его побить, дополнительные баллы будут для тех, кто попадет в топ-10 и топ-30 по итогам этой недели.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='user_id', index_label=\"session_id\"):\n",
    "    # turn predictions into data frame and save as csv file\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_to_submission_file ''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Пути улучшения\n",
    "На этой неделе дается много времени на соревнование. Не забывайте вносить хорошие идеи, к которым Вы пришли по ходу соревнования, в финальный проект (.pdf или .ipynb).\n",
    "Что можно попробовать:\n",
    " - Использовать ранее построенные признаки для улучшения модели (проверить их можно на меньшей выборке по 150 пользователям – это быстрее)\n",
    " - Настроить параметры моделей (например, коэффициенты регуляризации)\n",
    " - Если позволяют мощности (или хватает терпения), можно попробовать смешивание (блендинг) ответов бустинга и линейной модели. [Вот](http://mlwave.com/kaggle-ensembling-guide/) один из самых известных тьюториалов по смешиванию ответов алгоритмов\n",
    " - Обратите внимание, что в соревновании также даны исходные данные о посещенных 550 пользователями веб-страницах (550 csv-файлов в *train.zip*). По этим данным можно сформировать свою обучающую выборку. \n",
    "\n",
    "На 6 неделе мы пройдем тьюториал по Vowpal Wabbit и попробуем его в деле – в соревновании."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [python3]",
   "language": "python",
   "name": "Python [python3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
